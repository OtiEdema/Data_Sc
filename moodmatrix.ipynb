{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNX4RGfbvwATPsoK72mKiPg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mpHNC33QV69",
        "outputId": "6c4df9dd-add7-4597-9514-32763155abf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l2\n"
      ],
      "metadata": {
        "id": "SUzQlAYanbCL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the dataset directories\n",
        "train_dir = r'/content/drive/MyDrive/emdect/archive (4)/train'  # Adjusted for Google Colab environment\n",
        "test_dir = r'/content/drive/MyDrive/emdect/archive (4)/test'   # Adjusted for Google Colab environment"
      ],
      "metadata": {
        "id": "SCpEKKVynijP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image dimensions\n",
        "img_width, img_height = 48, 48\n",
        "\n",
        "# Parameters\n",
        "batch_size = 128  # Increased batch size\n",
        "epochs = 300  # Extended training duration\n",
        "num_classes = 7\n",
        "learning_rate = 0.0001  # Adjusted learning rate\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2]\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Loading training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Loading validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 100:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * np.exp(-0.1)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Model definition with added complexity and regularization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(img_width, img_height, 1), kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for early stopping, learning rate reduction, and learning rate scheduling\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping, reduce_lr, lr_scheduler],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the model using the .keras extension for the native Keras format\n",
        "model.save('emotion_model.keras')\n",
        "\n",
        "# Plotting training history\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AMRrtL8-80BF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}